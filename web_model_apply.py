#!/usr/bin/env python3
"""
Webæ¨¡å‹æ‡‰ç”¨å·¥å…· - è¼¸å…¥MIXéŸ³é »ï¼Œç”ŸæˆPREDéŸ³é »
åŸºæ–¼ test_my_models.py çš„ç°¡åŒ–ç‰ˆæœ¬ï¼Œå°ˆæ³¨æ–¼å–®ä¸€æ¨¡å‹æ¨ç†
"""

import os
import sys
import torch
import torchaudio
import time
from pathlib import Path

def setup_device():
    """è¨­ç½®è¨ˆç®—è¨­å‚™"""
    if torch.cuda.is_available():
        device = torch.device('cuda')
        print(f"âœ… ä½¿ç”¨GPU: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device('cpu')
        print("âš ï¸ ä½¿ç”¨CPU (æœƒæ¯”è¼ƒæ…¢)")
    
    return device

def load_model(model_path, device):
    """
    è¼‰å…¥æ¨¡å‹
    """
    print(f"ğŸ”„ è¼‰å…¥æ¨¡å‹: {os.path.basename(model_path)}")
    
    try:
        # æ·»åŠ çˆ¶ç›®éŒ„åˆ°Pythonè·¯å¾‘
        import sys
        import os
        parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        if parent_dir not in sys.path:
            sys.path.insert(0, parent_dir)
        
        # å°å…¥æ¨¡å‹æ¶æ§‹
        from src.training.dcc_tf_binaural import Net
        
        # è¼‰å…¥checkpoint
        checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
        model_state = checkpoint['model_state_dict']
        
        # å¾æ¨¡å‹state_dictæ¨æ–·æ¨¡å‹åƒæ•¸
        if 'label_embedding.0.weight' in model_state:
            n_labels = model_state['label_embedding.0.weight'].shape[1]
        else:
            n_labels = 20  # é»˜èªå€¼
            
        # æ¨æ–·model_dim
        if 'mask_gen.encoder.dcc_layers.dcc_0.layers.0.bias' in model_state:
            model_dim = model_state['mask_gen.encoder.dcc_layers.dcc_0.layers.0.bias'].shape[0]
        else:
            model_dim = 256  # é»˜èªå€¼
            
        # æ¨æ–·decoderå±¤æ•¸
        decoder_layers = 1  # é»˜èª1å±¤
        for i in range(10):
            if f'mask_gen.decoder.tf_dec_layers.{i}.self_attn.in_proj_weight' in model_state:
                decoder_layers = i + 1
            else:
                break
                
        print(f"ğŸ” æ¨¡å‹åƒæ•¸: æ¨™ç±¤={n_labels}, ç¶­åº¦={model_dim}, Decoderå±¤æ•¸={decoder_layers}")
        
        # å‰µå»ºæ¨¡å‹å¯¦ä¾‹
        model = Net(
            label_len=n_labels,
            model_dim=model_dim, 
            num_dec_layers=decoder_layers,
            L=32,
            num_enc_layers=10,
            dec_buf_len=13,
            dec_chunk_size=13,
            use_pos_enc=True,
            conditioning="mult",
            out_buf_len=4
        )
        
        # è¼‰å…¥æ¬Šé‡
        model.load_state_dict(model_state)
        model.to(device)
        model.eval()
        
        epoch = checkpoint.get('epoch', 0)
        print(f"âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸ (Epoch: {epoch})")
        return model, epoch
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {str(e)}")
        raise

def process_audio(model, audio_path, output_dir, device):
    """
    è™•ç†éŸ³é »æ–‡ä»¶
    """
    print(f"\nğŸµ è™•ç†éŸ³é »: {os.path.basename(audio_path)}")
    
    # è¼‰å…¥éŸ³é »
    try:
        mixture, sr = torchaudio.load(audio_path)
        print(f"   åŸå§‹æ ¼å¼: {mixture.shape}, æ¡æ¨£ç‡: {sr}")
    except Exception as e:
        print(f"âŒ éŸ³é »è¼‰å…¥å¤±æ•—: {e}")
        return None
    
    # ç¢ºä¿æ˜¯é›™è²é“
    if mixture.shape[0] == 1:
        mixture = mixture.repeat(2, 1)
        print("   è½‰æ›ç‚ºé›™è²é“")
    elif mixture.shape[0] > 2:
        mixture = mixture[:2]
        print("   æˆªå–å‰å…©å€‹è²é“")
    
    # é‡æ¡æ¨£åˆ°44.1kHz (å¦‚æœéœ€è¦)
    if sr != 44100:
        resampler = torchaudio.transforms.Resample(sr, 44100)
        mixture = resampler(mixture)
        sr = 44100
        print(f"   é‡æ¡æ¨£åˆ°44.1kHz")
    
    # ç§»åˆ°GPU
    mixture = mixture.to(device)
    
    # æº–å‚™æ¨™ç±¤å‘é‡ (å…¨1è¡¨ç¤ºè™•ç†æ‰€æœ‰è²éŸ³)
    label_vector = torch.ones(1, 20, device=device)
    
    # æº–å‚™æ¨¡å‹è¼¸å…¥
    inputs = {
        'mixture': mixture.unsqueeze(0),  # æ·»åŠ batchç¶­åº¦
        'label_vector': label_vector
    }
    
    # æ¨ç†
    print("   ğŸ”„ åŸ·è¡Œæ¨ç†...")
    start_time = time.time()
    
    with torch.no_grad():
        output = model(inputs)
    
    inference_time = time.time() - start_time
    audio_duration = mixture.shape[1] / sr
    
    print(f"   âš¡ æ¨ç†å®Œæˆ: {inference_time:.3f}ç§’ (éŸ³é »é•·åº¦: {audio_duration:.1f}ç§’)")
    print(f"   ğŸ“Š å¯¦æ™‚å€æ•¸: {audio_duration/inference_time:.1f}x")
    
    # ç²å–è¼¸å‡ºéŸ³é »
    pred_audio = output['x'].squeeze(0).cpu()  # ç§»é™¤batchç¶­åº¦ä¸¦ç§»åˆ°CPU
    
    # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # ç”Ÿæˆè¼¸å‡ºæª”å
    input_name = Path(audio_path).stem
    output_path = os.path.join(output_dir, f"{input_name}_pred.wav")
    
    # ä¿å­˜é æ¸¬éŸ³é »
    torchaudio.save(output_path, pred_audio, sr)
    print(f"   ğŸ’¾ ä¿å­˜é æ¸¬éŸ³é »: {output_path}")
    
    return output_path

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ¯ Webæ¨¡å‹æ‡‰ç”¨å·¥å…·")
    print("=" * 50)
    
    # é…ç½®
    model_path = "D:/data_output/eval/Third_200.pt"
    output_dir = "D:/data_output/eval/web_data"
    
    # é€™è£¡è¨­ç½®ä½ çš„è¼¸å…¥éŸ³é »è·¯å¾‘
    # ä¿®æ”¹ä¸‹é¢é€™è¡Œä¾†æŒ‡å®šä½ è¦è™•ç†çš„éŸ³é »æ–‡ä»¶
    input_audio_path = "D:/data_output/eval/web_data/sample_847_mixture.wav"
    
    print(f"ğŸ“ æ¨¡å‹è·¯å¾‘: {model_path}")
    print(f"ğŸ“ è¼¸å‡ºç›®éŒ„: {output_dir}")
    print(f"ğŸµ è¼¸å…¥éŸ³é »: {input_audio_path}")
    
    # æª¢æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return
    
    if not os.path.exists(input_audio_path):
        print(f"âŒ è¼¸å…¥éŸ³é »æ–‡ä»¶ä¸å­˜åœ¨: {input_audio_path}")
        print("ğŸ’¡ è«‹ä¿®æ”¹ input_audio_path è®Šæ•¸æŒ‡å‘ä½ çš„éŸ³é »æ–‡ä»¶")
        return
    
    # è¨­ç½®è¨­å‚™
    device = setup_device()
    
    # è¼‰å…¥æ¨¡å‹
    try:
        model, epoch = load_model(model_path, device)
    except Exception as e:
        print(f"âŒ ç„¡æ³•è¼‰å…¥æ¨¡å‹: {e}")
        return
    
    # è™•ç†éŸ³é »
    try:
        output_path = process_audio(model, input_audio_path, output_dir, device)
        
        if output_path:
            print(f"\nğŸ‰ è™•ç†å®Œæˆï¼")
            print(f"ğŸ“ è¼¸å‡ºæ–‡ä»¶: {output_path}")
            print(f"ğŸ’¡ ä½ å¯ä»¥æ’­æ”¾é€™å€‹æ–‡ä»¶ä¾†è½å–èªéŸ³åˆ†é›¢æ•ˆæœ")
        else:
            print(f"\nâŒ è™•ç†å¤±æ•—")
            
    except Exception as e:
        print(f"âŒ éŸ³é »è™•ç†å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
